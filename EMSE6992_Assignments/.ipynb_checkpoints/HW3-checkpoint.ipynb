{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 3\n",
    "\n",
    "### Due by 11:59pm on 30 November ( submit within Portfolio )\n",
    "\n",
    "For each instruction, show your code and execution within the Jupyter Notebook.  Download example files from:\n",
    " - https://github.com/bsharvey/EMSEDataAnalytics\n",
    " - files are located in the auto_examples_jupyter directory\n",
    "\n",
    "For HW3 we will be using scikit-learn. Follow the instructions and use the examples provided within the instruction that use the Iris dataset.\n",
    "\n",
    "Once complete, upload your results to Github and update the Assignment 3 link within your portfolio's.\n",
    "\n",
    "Instruction 1: Provide an example of concatenating multiple feature extraction methods using your dataset.\n",
    "\n",
    "In many real-world examples, there are many ways to extract features from a dataset. Often it is beneficial to combine several methods to obtain good performance. This example shows how to use FeatureUnion to combine features obtained by PCA and univariate selection.\n",
    "Combining features using this transformer has the benefit that it allows cross validation and grid searches over the whole process.\n",
    "The combination used in this example is not particularly helpful on this dataset and is only used to illustrate the usage of FeatureUnion.\n",
    "\n",
    "Example file located in: auto_examples_jupyter/plot_feature_stacker.ipynb\n",
    " - https://github.com/bsharvey/EMSEDataAnalytics/blob/master/auto_examples_jupyter/plot_feature_stacker.ipynb\n",
    "    \n",
    "\n",
    "### Applications\n",
    "Instruction 2: Provide an example of Outlier detection on your dataset.\n",
    "\n",
    "This example illustrates the need for robust covariance estimation on a real data set. It is useful both for outlier detection and for a better understanding of the data structure.\n",
    "We selected two sets of two variables from the Boston housing data set as an illustration of what kind of analysis can be done with several outlier detection tools. For the purpose of visualization, we are working with two-dimensional examples, but one should be aware that things are not so trivial in high-dimension, as it will be pointed out.\n",
    "In both examples below, the main result is that the empirical covariance estimate, as a non-robust one, is highly influenced by the heterogeneous structure of the observations. Although the robust covariance estimate is able to focus on the main mode of the data distribution, it sticks to the assumption that the data should be Gaussian distributed, yielding some biased estimation of the data structure, but yet accurate to some extent. The One-Class SVM does not assume any parametric form of the data distribution and can therefore model the complex shape of the data much better.\n",
    "\n",
    "Example file located in: auto_examples_jupyter/applications/plot_outlier_detection_housing.ipynb\n",
    " - https://github.com/bsharvey/EMSEDataAnalytics/blob/master/auto_examples_jupyter/applications/plot_outlier_detection_housing.ipynb\n",
    "\n",
    "### Classification\n",
    "Instruction 3: Provide an example of Classifier Comparison using yoru dataset\n",
    "\n",
    "A comparison of a several classifiers in scikit-learn on synthetic datasets. The point of this example is to illustrate the nature of decision boundaries of different classifiers. This should be taken with a grain of salt, as the intuition conveyed by these examples does not necessarily carry over to real datasets.\n",
    "Particularly in high-dimensional spaces, data can more easily be separated linearly and the simplicity of classifiers such as naive Bayes and linear SVMs might lead to better generalization than is achieved by other classifiers.\n",
    "The plots show training points in solid colors and testing points semi-transparent. The lower right shows the classification accuracy on the test set.\n",
    "auto_examples_jupyter/Classification/plot_classifier_comparison. ipynb\n",
    "Plot classification probability\n",
    "Plot the classification probability for different classifiers. We use a 3 class dataset, and we classify it with a Support Vector classifier, L1 and L2 penalized logistic regression with either a One-Vs-Rest or multinomial setting, and Gaussian process classification.\n",
    "The logistic regression is not a multiclass classifier out of the box. As a result it can identify only the first class.\n",
    "\n",
    "Example file located in: auto_examples_jupyter/auto_examples_jupyter/Classification/plot_lda_qda.ipynb\n",
    " - https://github.com/bsharvey/EMSEDataAnalytics/blob/master/auto_examples_jupyter/classification/plot_lda_qda.ipynb\n",
    "\n",
    "### Clustering\n",
    "Instruction 4: Provide an example of K-means Clustering using your dataset\n",
    "\n",
    "The plots display firstly what a K-means algorithm would yield using three clusters. It is then shown what the effect of a bad initialization is on the classification process: By setting n_init to only 1 (default is 10), the amount of times that the algorithm will be run with different centroid seeds is reduced. The next plot displays what using eight clusters would deliver and finally the ground truth.\n",
    "\n",
    "Example file located in: auto_examples_jupyter/clustering/plot_cluster_iris.ipynb\n",
    " - https://github.com/bsharvey/EMSEDataAnalytics/blob/master/auto_examples_jupyter/cluster/plot_cluster_iris.ipynb\n",
    "\n",
    "\n",
    "### Covariance Estimation\n",
    "Instruction 4: Provide an example of Outlier detection with covariance estimation using your dataset.\n",
    "\n",
    "When the amount of contamination is known, this example illustrates three different ways of performing Novelty and Outlier Detection:\n",
    "•\tbased on a robust estimator of covariance, which is assuming that the data are Gaussian distributed and performs better than the One-Class SVM in that case.\n",
    "•\tusing the One-Class SVM and its ability to capture the shape of the data set, hence performing better when the data is strongly non-Gaussian, i.e. with two well-separated clusters;\n",
    "•\tusing the Isolation Forest algorithm, which is based on random forests and hence more adapted to large-dimensional settings, even if it performs quite well in the examples below.\n",
    "•\tusing the Local Outlier Factor to measure the local deviation of a given data point with respect to its neighbors by comparing their local density.\n",
    "The ground truth about inliers and outliers is given by the points colors while the orange-filled area indicates which points are reported as inliers by each method.\n",
    "Here, we assume that we know the fraction of outliers in the datasets. Thus rather than using the ‘predic\n",
    "\n",
    "Example file located in: auto_examples_jupyter/Covariance/plot_outlier_detection.ipynb\n",
    " - https://github.com/bsharvey/EMSEDataAnalytics/blob/master/auto_examples_jupyter/covariance/plot_outlier_detection.ipynb\n",
    "\n",
    "### Cross decomposition\n",
    "\n",
    "Instruction 5: Provide a comparison of cross decomposition methods using your dataset\n",
    "\n",
    "Simple usage of various cross decomposition algorithms: - PLSCanonical - PLSRegression, with multivariate response, a.k.a. PLS2 - PLSRegression, with univariate response, a.k.a. PLS1 - CCA\n",
    "Given 2 multivariate covarying two-dimensional datasets, X, and Y, PLS extracts the ‘directions of covariance’, i.e. the components of each datasets that explain the most shared variance between both datasets. This is apparent on the scatterplot matrix display: components 1 in dataset X and dataset Y are maximally correlated (points lie around the first diagonal). This is also true for components 2 in both dataset, however, the correlation across datasets for different components is weak: the point cloud is very spherical.\n",
    "\n",
    "Example file located in: auto_examples_jupyter/cross_decomposition/plot_compare_cross_decomposition.ipynb\n",
    " - https://github.com/bsharvey/EMSEDataAnalytics/blob/master/auto_examples_jupyter/cross_decomposition/plot_compare_cross_decomposition.ipynb\n",
    "\n",
    "### Decomposition\n",
    "Instruction 6: Provide an example of PCA using your dataset\n",
    "\n",
    "Principal Component Analysis applied to the Iris dataset.\n",
    "\n",
    "Example file located in: auto_examples_jupyter/decomposition/plot_pca_iris.ipynb\n",
    " - https://github.com/bsharvey/EMSEDataAnalytics/blob/master/auto_examples_jupyter/decomposition/plot_pca_iris.ipynb\n",
    "\n",
    "Instruction 7: Provide an example of a Comparison of LDA and PCA 2D projection of your dataset\n",
    "\n",
    "The Iris dataset represents 3 kind of Iris flowers (Setosa, Versicolour and Virginica) with 4 attributes: sepal length, sepal width, petal length and petal width.\n",
    "Principal Component Analysis (PCA) applied to this data identifies the combination of attributes (principal components, or directions in the feature space) that account for the most variance in the data. Here we plot the different samples on the 2 first principal components.\n",
    "Linear Discriminant Analysis (LDA) tries to identify attributes that account for the most variance between classes. In particular, LDA, in contrast to PCA, is a supervised method, using known class labels.\n",
    "\n",
    "Example file located in: auto_examples_jupyter/decomposition/plot_pca_vs_lda.ipynb\n",
    " - https://github.com/bsharvey/EMSEDataAnalytics/blob/master/auto_examples_jupyter/decomposition/plot_pca_vs_lda.ipynb\n",
    "\n",
    "### Ensemble methods\n",
    "Instruction 8: Provide an example of Plotting the decision surfaces of ensembles of trees using your dataset\n",
    "\n",
    "Plot the decision surfaces of forests of randomized trees trained on pairs of features of the iris dataset.\n",
    "\n",
    "Example file located in: auto_examples_jupyter/ensemble/plot_forest_iris.ipynb\n",
    " - https://github.com/bsharvey/EMSEDataAnalytics/blob/master/auto_examples_jupyter/ensemble/plot_forest_iris.ipynb\n",
    "\n",
    "### Tutorial exercises\n",
    "Instruction 9: Provide an example of SVM using your dataset\n",
    "\n",
    "A tutorial exercise for using different SVM kernels.\n",
    "This exercise is used in the Using kernels part of the Supervised learning: predicting an output variable from high-dimensional observations section of the A tutorial on statistical-learning for scientific data processing.\n",
    "plot_iris_exercise.ipynb\n",
    "Cross-validation on Digits Dataset Exercise\n",
    "A tutorial exercise using Cross-validation with an SVM on the Digits dataset.\n",
    "\n",
    "Example file located in: auto_examples_jupyter/exercises/plot_cv_digits.ipynb\n",
    " - https://github.com/bsharvey/EMSEDataAnalytics/blob/master/auto_examples_jupyter/exercises/plot_cv_digits.ipynb\n",
    "\n",
    "### Feature Selection\n",
    "Instruction 10: Provide an example of Feature selection using SelectFromModel and LassoCV using your dataset\n",
    "\n",
    "Use SelectFromModel meta-transformer along with Lasso to select the best couple of features from the Boston dataset.\n",
    "plot_select_from_model_boston.ipynb\n",
    "Recursive feature elimination with cross-validation\n",
    "A recursive feature elimination example with automatic tuning of the number of features selected with cross-validation.\n",
    "\n",
    "Example file located in: auto_examples_jupyter/feature_selection/plot_select_from_model_boston.ipynb\n",
    " - https://github.com/bsharvey/EMSEDataAnalytics/blob/master/auto_examples_jupyter/feature_selection/plot_select_from_model_boston.ipynb\n",
    "\n",
    "Instruction 11: Provide an example of Univariate Feature Selection using your dataset.\n",
    "\n",
    "An example showing univariate feature selection.\n",
    "Noisy (non informative) features are added to the iris data and univariate feature selection is applied. For each feature, we plot the p-values for the univariate feature selection and the corresponding weights of an SVM. We can see that univariate feature selection selects the informative features and that these have larger SVM weights.\n",
    "In the total set of features, only the 4 first ones are significant. We can see that they have the highest score with univariate feature selection. The SVM assigns a large weight to one of these features, but also Selects many of the non-informative features. Applying univariate feature selection before the SVM increases the SVM weight attributed to the significant features, and will thus improve classification\n",
    "\n",
    "Example file located in: auto_examples_jupyter/feature_selection/plot_feature_selection.ipynb\n",
    " - https://github.com/bsharvey/EMSEDataAnalytics/blob/master/auto_examples_jupyter/feature_selection/plot_feature_selection.ipynb\n",
    "\n",
    "\n",
    "### Gaussian Process for Machine Learning\n",
    "Instruction 12: Provide an example of Gaussian process classification (GPC) on your dataset\n",
    "\n",
    "This example illustrates the predicted probability of GPC for an isotropic and anisotropic RBF kernel on a two-dimensional version for the iris-dataset. The anisotropic RBF kernel obtains slightly higher log-marginal-likelihood by assigning different length-scales to the two feature dimensions.\n",
    "\n",
    "Example file located in: auto_examples_jupyter/gausian_process/plot_gpc_iris.ipynb\n",
    " - https://github.com/bsharvey/EMSEDataAnalytics/blob/master/auto_examples_jupyter/gaussian_process/plot_gpc_iris.ipynb\n",
    "\n",
    "### Generalized Linear Models\n",
    "Instruction 13: Provide an example of Plotting multi-class SGD on your dataset\n",
    "\n",
    "Plot decision surface of multi-class SGD on iris dataset. The hyperplanes corresponding to the three one-versus-all (OVA) classifiers are represented by the dashed lines.\n",
    "plot_sgd_iris.ipynb\n",
    "Logistic Regression 3-class Classifier\n",
    "Show below is a logistic-regression classifiers decision boundaries on the iris <https://en.wikipedia.org/wiki/Iris_flower_data_set>_ dataset. The datapoints are colored according to their labels.\n",
    "\n",
    "Example file located in: auto_examples_jupyter/linear_models/plot_iris_logistic.ipynb\n",
    " - https://github.com/bsharvey/EMSEDataAnalytics/blob/master/auto_examples_jupyter/linear_model/plot_iris_logistic.ipynb\n",
    "\n",
    "### Model Selection\n",
    "Instruction 14: Provide an example of Underfitting vs. Overfitting using your dataset\n",
    "\n",
    "This example demonstrates the problems of underfitting and overfitting and how we can use linear regression with polynomial features to approximate nonlinear functions. The plot shows the function that we want to approximate, which is a part of the cosine function. In addition, the samples from the real function and the approximations of different models are displayed. The models have polynomial features of different degrees. We can see that a linear function (polynomial with degree 1) is not sufficient to fit the training samples. This is called underfitting. A polynomial of degree 4 approximates the true function almost perfectly. However, for higher degrees the model will overfit the training data, i.e. it learns the noise of the training data. We evaluate quantitatively overfitting / underfitting by using cross-validation. We calculate the mean squared error (MSE) on the validation set, the higher, the less likely the model generalizes correctly from the training data.\n",
    "\n",
    "Example file located in: auto_examples_jupyter/model_selection/plot_underfitting_overfitting.ipynb\n",
    " - https://github.com/bsharvey/EMSEDataAnalytics/blob/master/auto_examples_jupyter/model_selection/plot_underfitting_overfitting.ipynb\n",
    "\n",
    "### Nearest Neighbors\n",
    "Instruction 15: Provide an example of Nearest Neighbors Classification using your dataset.\n",
    "\n",
    "Sample usage of Nearest Neighbors classification. It will plot the decision boundaries for each class.\n",
    "\n",
    "Example file located in: auto_examples_jupyter/neighbors/plot_classification.ipynb\n",
    " - https://github.com/bsharvey/EMSEDataAnalytics/blob/master/auto_examples_jupyter/neighbors/plot_classification.ipynb\n",
    "\n",
    "### Neural Networks\n",
    "Instruction 16: Provide an example of Varying regularization in Multi-layer Perceptron using your dataset\n",
    "\n",
    "A comparison of different values for regularization parameter ‘alpha’ on synthetic datasets. The plot shows that different alphas yield different decision functions.\n",
    "Alpha is a parameter for regularization term, aka penalty term, that combats overfitting by constraining the size of the weights. Increasing alpha may fix high variance (a sign of overfitting) by encouraging smaller weights, resulting in a decision boundary plot that appears with lesser curvatures. Similarly, decreasing alpha may fix high bias (a sign of underfitting) by encouraging larger weights, potentially resulting in a more complicated decision boundary.\n",
    "\n",
    "Example file located in: auto_examples_jupyter/neural_networks/plot_mlp_alpha.ipynb\n",
    " - https://github.com/bsharvey/EMSEDataAnalytics/blob/master/auto_examples_jupyter/neural_networks/plot_mlp_alpha.ipynb\n",
    "\n",
    "### Preprocessing\n",
    "Instruction 17: Provide an example of Importance of Feature Scaling using your dataset\n",
    "\n",
    "Feature scaling though standardization (or Z-score normalization) can be an important preprocessing step for many machine learning algorithms. Standardization involves rescaling the features such that they have the properties of a standard normal distribution with a mean of zero and a standard deviation of one.\n",
    "While many algorithms (such as SVM, K-nearest neighbors, and logistic regression) require features to be normalized, intuitively we can think of Principle Component Analysis (PCA) as being a prime example of when normalization is important. In PCA we are interested in the components that maximize the variance. If one component (e.g. human height) varies less than another (e.g. weight) because of their respective scales (meters vs. kilos), PCA might determine that the direction of maximal variance more closely corresponds with the ‘weight’ axis, if those features are not scaled. As a change in height of one meter can be considered much more important than the change in weight of one kilogram, this is clearly incorrect.\n",
    "To illustrate this, PCA is performed comparing the use of data with StandardScaler applied, to unscaled data. The results are visualized and a clear difference noted. The 1st principal component in the unscaled set can be seen. It can be seen that feature #13 dominates the direction, being a whole two orders of magnitude above the other features. This is contrasted when observing the principal component for the scaled version of the data. In the scaled version, the orders of magnitude are roughly the same across all the features.\n",
    "The dataset used is the Wine Dataset available at UCI. This dataset has continuous features that are heterogeneous in scale due to differing properties that they measure (i.e alcohol content, and malic acid).\n",
    "The transformed data is then used to train a naive Bayes classifier, and a clear difference in prediction accuracies is observed wherein the dataset which is scaled before PCA vastly outperforms the unscaled version.\n",
    "\n",
    "Example file located in: auto_examples_jupyter/preprocessing/plot_scaling_importance.ipynb\n",
    " - https://github.com/bsharvey/EMSEDataAnalytics/blob/master/auto_examples_jupyter/preprocessing/plot_scaling_importance.ipynb\n",
    "\n",
    "Instruction 18: Provide an example of a comparison of the effect of different scalers on your dataset with outliers\n",
    "\n",
    "Feature 0 (median income in a block) and feature 5 (number of households) of the California housing dataset have very different scales and contain some very large outliers. These two characteristics lead to difficulties to visualize the data and, more importantly, they can degrade the predictive performance of many machine learning algorithms. Unscaled data can also slow down or even prevent the convergence of many gradient-based estimators.\n",
    "Indeed many estimators are designed with the assumption that each feature takes values close to zero or more importantly that all features vary on comparable scales. In particular, metric-based and gradient-based estimators often assume approximately standardized data (centered features with unit variances). A notable exception are decision tree-based estimators that are robust to arbitrary scaling of the data.\n",
    "This example uses different scalers, transformers, and normalizers to bring the data within a pre-defined range.\n",
    "Scalers are linear (or more precisely affine) transformers and differ from each other in the way to estimate the parameters used to shift and scale each feature.\n",
    "QuantileTransformer provides a non-linear transformation in which distances between marginal outliers and inliers are shrunk.\n",
    "Unlike the previous transformations, normalization refers to a per sample transformation instead of a per feature transformation.\n",
    "The following code is a bit verbose, feel free to jump directly to the analysis of the results.\n",
    "\n",
    "Example file located in: auto_examples_jupyter/preprocessing/plot_all_scaling.ipynb\n",
    " - https://github.com/bsharvey/EMSEDataAnalytics/blob/master/auto_examples_jupyter/preprocessing/plot_all_scaling.ipynb\n",
    "\n",
    "### Semi Supervised Classification\n",
    "Instruction 19: Provide an example of the decision boundary of label propagation versus SVM on your dataset\n",
    "\n",
    "Comparison for decision boundary generated on iris dataset between Label Propagation and SVM.\n",
    "This demonstrates Label Propagation learning a good boundary even with a small amount of labeled data.\n",
    "\n",
    "Example file located in: auto_examples_jupyter/semi_supervised/plot_label_propagation_versus_svm_iris.ipynb\n",
    " - https://github.com/bsharvey/EMSEDataAnalytics/blob/master/auto_examples_jupyter/semi_supervised/plot_label_propagation_versus_svm_iris.ipynb\n",
    "\n",
    "### Support Vector Machines\n",
    "Instruction 20: Provide an example of Plot different SVM classifiers in your dataset\n",
    "Comparison of different linear SVM classifiers on a 2D projection of the iris dataset. We only consider the first 2 features of this dataset:\n",
    "•\tSepal length\n",
    "•\tSepal width\n",
    "This example shows how to plot the decision surface for four SVM classifiers with different kernels.\n",
    "The linear models LinearSVC() and SVC(kernel='linear') yield slightly different decision boundaries. This can be a consequence of the following differences:\n",
    "•\tLinearSVC minimizes the squared hinge loss while SVC minimizes the regular hinge loss.\n",
    "•\tLinearSVC uses the One-vs-All (also known as One-vs-Rest) multiclass reduction while SVC uses the One-vs-One multiclass reduction.\n",
    "Both linear models have linear decision boundaries (intersecting hyperplanes) while the non-linear kernel models (polynomial or Gaussian RBF) have more flexible non-linear decision boundaries with shapes that depend on the kind of kernel and its parameters.\n",
    "\n",
    "Example file located in: auto_examples_jupyter/svm/plot_iris.ipynb\n",
    " - https://github.com/bsharvey/EMSEDataAnalytics/blob/master/auto_examples_jupyter/svm/plot_iris.ipynb\n",
    "\n",
    "### Decision Trees\n",
    "Instruction 21: Provide an example of plotting the decision surface of a decision tree on your dataset\n",
    "\n",
    "Plot the decision surface of a decision tree trained on pairs of features of the iris dataset.\n",
    "See decision tree for more information on the estimator.\n",
    "For each pair of iris features, the decision tree learns decision boundaries made of combinations of simple thresholding rules inferred from the training samples.\n",
    "\n",
    "Example file located in: auto_examples_jupyter/tree/plot_iris.ipynb\n",
    " - https://github.com/bsharvey/EMSEDataAnalytics/blob/master/auto_examples_jupyter/tree/plot_iris.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Pattern3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a0c6ef0fca00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmrjob\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbs4\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mPattern3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Pattern3'"
     ]
    }
   ],
   "source": [
    "#Instruction 1: Provide an example of concatenating multiple feature extraction methods using your dataset.\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import jupyter\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "import requests\n",
    "import networkx as nx\n",
    "import mrjob\n",
    "import bs4\n",
    "import Pattern3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>ST_CASE</th>\n",
       "      <th>VE_TOTAL</th>\n",
       "      <th>VE_FORMS</th>\n",
       "      <th>PVH_INVL</th>\n",
       "      <th>PEDS</th>\n",
       "      <th>PERNOTMVIT</th>\n",
       "      <th>...</th>\n",
       "      <th>NOT_MIN</th>\n",
       "      <th>ARR_HOUR</th>\n",
       "      <th>ARR_MIN</th>\n",
       "      <th>HOSP_HR</th>\n",
       "      <th>HOSP_MN</th>\n",
       "      <th>CF1</th>\n",
       "      <th>CF2</th>\n",
       "      <th>CF3</th>\n",
       "      <th>FATALS</th>\n",
       "      <th>DRUNK_DR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-86.383703</td>\n",
       "      <td>33.791964</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-85.888306</td>\n",
       "      <td>33.984661</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10002</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>21</td>\n",
       "      <td>33</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-86.621472</td>\n",
       "      <td>34.749467</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>11</td>\n",
       "      <td>54</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-86.857011</td>\n",
       "      <td>33.485914</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>12</td>\n",
       "      <td>33</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-87.551831</td>\n",
       "      <td>33.168556</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10005</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-88.107933</td>\n",
       "      <td>30.661678</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>10006</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>14</td>\n",
       "      <td>32</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-86.220731</td>\n",
       "      <td>34.270869</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>10007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>21</td>\n",
       "      <td>38</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-85.799858</td>\n",
       "      <td>34.561072</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>10008</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>14</td>\n",
       "      <td>55</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-85.291389</td>\n",
       "      <td>33.010019</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>10009</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-85.970611</td>\n",
       "      <td>32.577275</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10010</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>17</td>\n",
       "      <td>45</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-86.464275</td>\n",
       "      <td>32.601461</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>10011</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>23</td>\n",
       "      <td>40</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-86.577525</td>\n",
       "      <td>34.015400</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>10012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-86.866353</td>\n",
       "      <td>34.054006</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>10013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-86.457942</td>\n",
       "      <td>34.408347</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>10014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-86.110833</td>\n",
       "      <td>33.896394</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>10015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-85.613056</td>\n",
       "      <td>34.377403</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>10016</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-87.217569</td>\n",
       "      <td>33.113853</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>10017</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-85.356303</td>\n",
       "      <td>32.612717</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>10018</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-86.608522</td>\n",
       "      <td>34.745875</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>10019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-86.587686</td>\n",
       "      <td>32.943233</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>10020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-85.310939</td>\n",
       "      <td>31.096008</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>10021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-86.063178</td>\n",
       "      <td>32.077636</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>10022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-88.055317</td>\n",
       "      <td>32.885183</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>10023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>18</td>\n",
       "      <td>50</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-86.737522</td>\n",
       "      <td>33.205572</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>10024</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-87.961681</td>\n",
       "      <td>34.819964</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>10025</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-86.863325</td>\n",
       "      <td>33.177500</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>10026</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>14</td>\n",
       "      <td>45</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-86.860561</td>\n",
       "      <td>32.303889</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>10027</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-85.901019</td>\n",
       "      <td>32.906178</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>10028</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>11</td>\n",
       "      <td>46</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-87.635192</td>\n",
       "      <td>34.744300</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>10029</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-86.334656</td>\n",
       "      <td>32.327300</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>10030</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>22</td>\n",
       "      <td>29</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30027</th>\n",
       "      <td>-88.083711</td>\n",
       "      <td>43.174092</td>\n",
       "      <td>29971</td>\n",
       "      <td>55</td>\n",
       "      <td>550500</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30028</th>\n",
       "      <td>-89.726589</td>\n",
       "      <td>43.428358</td>\n",
       "      <td>29972</td>\n",
       "      <td>55</td>\n",
       "      <td>550501</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30029</th>\n",
       "      <td>-89.402381</td>\n",
       "      <td>43.377378</td>\n",
       "      <td>29973</td>\n",
       "      <td>55</td>\n",
       "      <td>550502</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30030</th>\n",
       "      <td>-87.852969</td>\n",
       "      <td>42.718372</td>\n",
       "      <td>29974</td>\n",
       "      <td>55</td>\n",
       "      <td>550503</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>13</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30031</th>\n",
       "      <td>-89.519464</td>\n",
       "      <td>44.025050</td>\n",
       "      <td>29975</td>\n",
       "      <td>55</td>\n",
       "      <td>550504</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30032</th>\n",
       "      <td>-88.914944</td>\n",
       "      <td>45.564692</td>\n",
       "      <td>29976</td>\n",
       "      <td>55</td>\n",
       "      <td>550505</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30033</th>\n",
       "      <td>-91.445906</td>\n",
       "      <td>44.209167</td>\n",
       "      <td>29977</td>\n",
       "      <td>55</td>\n",
       "      <td>550506</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30034</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29978</td>\n",
       "      <td>55</td>\n",
       "      <td>550507</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30035</th>\n",
       "      <td>-90.760842</td>\n",
       "      <td>44.180917</td>\n",
       "      <td>29979</td>\n",
       "      <td>55</td>\n",
       "      <td>550508</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30036</th>\n",
       "      <td>-88.522328</td>\n",
       "      <td>45.030411</td>\n",
       "      <td>29980</td>\n",
       "      <td>55</td>\n",
       "      <td>550509</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30037</th>\n",
       "      <td>-88.627744</td>\n",
       "      <td>44.877169</td>\n",
       "      <td>29981</td>\n",
       "      <td>55</td>\n",
       "      <td>550510</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30038</th>\n",
       "      <td>-90.856797</td>\n",
       "      <td>43.654272</td>\n",
       "      <td>29982</td>\n",
       "      <td>55</td>\n",
       "      <td>550511</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30039</th>\n",
       "      <td>-105.528778</td>\n",
       "      <td>41.290969</td>\n",
       "      <td>29983</td>\n",
       "      <td>56</td>\n",
       "      <td>560001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30040</th>\n",
       "      <td>-104.056131</td>\n",
       "      <td>41.914739</td>\n",
       "      <td>29984</td>\n",
       "      <td>56</td>\n",
       "      <td>560002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30041</th>\n",
       "      <td>-105.407564</td>\n",
       "      <td>41.162656</td>\n",
       "      <td>29985</td>\n",
       "      <td>56</td>\n",
       "      <td>560003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>46</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30042</th>\n",
       "      <td>-105.723997</td>\n",
       "      <td>43.985064</td>\n",
       "      <td>29986</td>\n",
       "      <td>56</td>\n",
       "      <td>560004</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30043</th>\n",
       "      <td>-106.202567</td>\n",
       "      <td>41.907183</td>\n",
       "      <td>29987</td>\n",
       "      <td>56</td>\n",
       "      <td>560005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30044</th>\n",
       "      <td>-104.813356</td>\n",
       "      <td>41.121325</td>\n",
       "      <td>29988</td>\n",
       "      <td>56</td>\n",
       "      <td>560006</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>22</td>\n",
       "      <td>37</td>\n",
       "      <td>22</td>\n",
       "      <td>49</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30045</th>\n",
       "      <td>-105.045000</td>\n",
       "      <td>42.344722</td>\n",
       "      <td>29989</td>\n",
       "      <td>56</td>\n",
       "      <td>560007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "      <td>58</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30046</th>\n",
       "      <td>-105.499733</td>\n",
       "      <td>41.272297</td>\n",
       "      <td>29990</td>\n",
       "      <td>56</td>\n",
       "      <td>560008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>19</td>\n",
       "      <td>45</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30047</th>\n",
       "      <td>-105.387297</td>\n",
       "      <td>41.148681</td>\n",
       "      <td>29991</td>\n",
       "      <td>56</td>\n",
       "      <td>560009</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30048</th>\n",
       "      <td>-106.992267</td>\n",
       "      <td>43.032011</td>\n",
       "      <td>29992</td>\n",
       "      <td>56</td>\n",
       "      <td>560010</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>55</td>\n",
       "      <td>15</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30049</th>\n",
       "      <td>-105.820367</td>\n",
       "      <td>42.826842</td>\n",
       "      <td>29993</td>\n",
       "      <td>56</td>\n",
       "      <td>560011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>99</td>\n",
       "      <td>98</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30050</th>\n",
       "      <td>-108.158411</td>\n",
       "      <td>43.495092</td>\n",
       "      <td>29994</td>\n",
       "      <td>56</td>\n",
       "      <td>560012</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>45</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30051</th>\n",
       "      <td>-104.850864</td>\n",
       "      <td>44.322725</td>\n",
       "      <td>29995</td>\n",
       "      <td>56</td>\n",
       "      <td>560013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30052</th>\n",
       "      <td>-107.931000</td>\n",
       "      <td>44.241800</td>\n",
       "      <td>29996</td>\n",
       "      <td>56</td>\n",
       "      <td>560014</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30053</th>\n",
       "      <td>-110.937158</td>\n",
       "      <td>42.003578</td>\n",
       "      <td>29997</td>\n",
       "      <td>56</td>\n",
       "      <td>560015</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30054</th>\n",
       "      <td>-108.393672</td>\n",
       "      <td>41.634439</td>\n",
       "      <td>29998</td>\n",
       "      <td>56</td>\n",
       "      <td>560016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>50</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30055</th>\n",
       "      <td>-106.331500</td>\n",
       "      <td>42.979200</td>\n",
       "      <td>29999</td>\n",
       "      <td>56</td>\n",
       "      <td>560017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30056</th>\n",
       "      <td>-109.510556</td>\n",
       "      <td>41.553194</td>\n",
       "      <td>30000</td>\n",
       "      <td>56</td>\n",
       "      <td>560018</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30057 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                X          Y  OBJECTID  STATE  ST_CASE  VE_TOTAL  VE_FORMS  \\\n",
       "0      -86.383703  33.791964         1      1    10001         1         1   \n",
       "1      -85.888306  33.984661         2      1    10002         2         2   \n",
       "2      -86.621472  34.749467         3      1    10003         1         1   \n",
       "3      -86.857011  33.485914         4      1    10004         1         1   \n",
       "4      -87.551831  33.168556         5      1    10005         2         2   \n",
       "5      -88.107933  30.661678         6      1    10006         2         2   \n",
       "6      -86.220731  34.270869         7      1    10007         1         1   \n",
       "7      -85.799858  34.561072         8      1    10008         2         2   \n",
       "8      -85.291389  33.010019         9      1    10009         1         1   \n",
       "9      -85.970611  32.577275        10      1    10010         2         2   \n",
       "10     -86.464275  32.601461        11      1    10011         2         2   \n",
       "11     -86.577525  34.015400        12      1    10012         1         1   \n",
       "12     -86.866353  34.054006        13      1    10013         1         1   \n",
       "13     -86.457942  34.408347        14      1    10014         1         1   \n",
       "14     -86.110833  33.896394        15      1    10015         1         1   \n",
       "15     -85.613056  34.377403        16      1    10016         2         2   \n",
       "16     -87.217569  33.113853        17      1    10017         2         2   \n",
       "17     -85.356303  32.612717        18      1    10018         2         2   \n",
       "18     -86.608522  34.745875        19      1    10019         1         1   \n",
       "19     -86.587686  32.943233        20      1    10020         1         1   \n",
       "20     -85.310939  31.096008        21      1    10021         1         1   \n",
       "21     -86.063178  32.077636        22      1    10022         1         1   \n",
       "22     -88.055317  32.885183        23      1    10023         1         1   \n",
       "23     -86.737522  33.205572        24      1    10024         2         2   \n",
       "24     -87.961681  34.819964        25      1    10025         1         1   \n",
       "25     -86.863325  33.177500        26      1    10026         2         2   \n",
       "26     -86.860561  32.303889        27      1    10027         1         1   \n",
       "27     -85.901019  32.906178        28      1    10028         1         1   \n",
       "28     -87.635192  34.744300        29      1    10029         2         2   \n",
       "29     -86.334656  32.327300        30      1    10030         3         3   \n",
       "...           ...        ...       ...    ...      ...       ...       ...   \n",
       "30027  -88.083711  43.174092     29971     55   550500        22        22   \n",
       "30028  -89.726589  43.428358     29972     55   550501         1         1   \n",
       "30029  -89.402381  43.377378     29973     55   550502         1         1   \n",
       "30030  -87.852969  42.718372     29974     55   550503         2         2   \n",
       "30031  -89.519464  44.025050     29975     55   550504         1         1   \n",
       "30032  -88.914944  45.564692     29976     55   550505         1         1   \n",
       "30033  -91.445906  44.209167     29977     55   550506         1         1   \n",
       "30034    0.000000   0.000000     29978     55   550507         1         1   \n",
       "30035  -90.760842  44.180917     29979     55   550508         1         1   \n",
       "30036  -88.522328  45.030411     29980     55   550509         1         1   \n",
       "30037  -88.627744  44.877169     29981     55   550510         1         1   \n",
       "30038  -90.856797  43.654272     29982     55   550511         2         2   \n",
       "30039 -105.528778  41.290969     29983     56   560001         1         1   \n",
       "30040 -104.056131  41.914739     29984     56   560002         1         1   \n",
       "30041 -105.407564  41.162656     29985     56   560003         1         1   \n",
       "30042 -105.723997  43.985064     29986     56   560004         2         2   \n",
       "30043 -106.202567  41.907183     29987     56   560005         1         1   \n",
       "30044 -104.813356  41.121325     29988     56   560006         3         1   \n",
       "30045 -105.045000  42.344722     29989     56   560007         1         1   \n",
       "30046 -105.499733  41.272297     29990     56   560008         1         1   \n",
       "30047 -105.387297  41.148681     29991     56   560009         1         1   \n",
       "30048 -106.992267  43.032011     29992     56   560010         2         2   \n",
       "30049 -105.820367  42.826842     29993     56   560011         1         1   \n",
       "30050 -108.158411  43.495092     29994     56   560012         2         2   \n",
       "30051 -104.850864  44.322725     29995     56   560013         1         1   \n",
       "30052 -107.931000  44.241800     29996     56   560014         2         2   \n",
       "30053 -110.937158  42.003578     29997     56   560015         2         2   \n",
       "30054 -108.393672  41.634439     29998     56   560016         1         1   \n",
       "30055 -106.331500  42.979200     29999     56   560017         1         1   \n",
       "30056 -109.510556  41.553194     30000     56   560018         2         1   \n",
       "\n",
       "       PVH_INVL  PEDS  PERNOTMVIT    ...     NOT_MIN  ARR_HOUR  ARR_MIN  \\\n",
       "0             0     0           0    ...          99         1        7   \n",
       "1             0     0           0    ...          99        21       33   \n",
       "2             0     0           0    ...          99        11       54   \n",
       "3             0     0           0    ...          99        12       33   \n",
       "4             0     0           0    ...          99        18       29   \n",
       "5             0     0           0    ...          99        14       32   \n",
       "6             0     0           0    ...          99        21       38   \n",
       "7             0     0           0    ...          99        14       55   \n",
       "8             0     0           0    ...          88        88       88   \n",
       "9             0     0           0    ...          99        17       45   \n",
       "10            0     0           0    ...          99        23       40   \n",
       "11            0     1           1    ...          99         6       15   \n",
       "12            0     0           0    ...          99         7       33   \n",
       "13            0     0           0    ...          99        16       22   \n",
       "14            0     0           0    ...          99        20       15   \n",
       "15            0     0           0    ...          99        18       21   \n",
       "16            0     0           0    ...          99         6       10   \n",
       "17            0     0           0    ...          99        10       29   \n",
       "18            0     0           0    ...          99         6       18   \n",
       "19            0     0           0    ...          99        21       20   \n",
       "20            0     0           0    ...          99         0       21   \n",
       "21            0     0           0    ...          99        11       10   \n",
       "22            0     0           0    ...          99        18       50   \n",
       "23            0     0           0    ...          99        11       26   \n",
       "24            0     0           0    ...          99         6       20   \n",
       "25            0     0           0    ...          99        14       45   \n",
       "26            0     0           0    ...          99        23       25   \n",
       "27            0     0           0    ...          99        11       46   \n",
       "28            0     1           1    ...          99        21       19   \n",
       "29            0     0           0    ...          99        22       29   \n",
       "...         ...   ...         ...    ...         ...       ...      ...   \n",
       "30027         0     0           0    ...          26        11       33   \n",
       "30028         0     0           0    ...          38         1       48   \n",
       "30029         0     0           0    ...          37        99       99   \n",
       "30030         0     0           0    ...          24        13       31   \n",
       "30031         0     0           0    ...          18         6       22   \n",
       "30032         0     0           0    ...          99        99       99   \n",
       "30033         0     0           0    ...          99        99       99   \n",
       "30034         0     0           0    ...          99        99       99   \n",
       "30035         0     0           0    ...          99        99       99   \n",
       "30036         0     1           1    ...          28         0       47   \n",
       "30037         0     0           0    ...          45        99       99   \n",
       "30038         0     0           0    ...          99        99       99   \n",
       "30039         0     0           0    ...          35         9       43   \n",
       "30040         0     0           0    ...          57         0       12   \n",
       "30041         0     0           0    ...          46         7       10   \n",
       "30042         0     0           0    ...           7        15       30   \n",
       "30043         0     0           0    ...          13         6       26   \n",
       "30044         2     0           0    ...          32        22       37   \n",
       "30045         0     0           0    ...          42        17       58   \n",
       "30046         0     0           0    ...          38        19       45   \n",
       "30047         0     0           0    ...          59        17       15   \n",
       "30048         0     0           0    ...          25        14       55   \n",
       "30049         0     0           0    ...          98        99       98   \n",
       "30050         0     0           0    ...          28        19       45   \n",
       "30051         0     0           0    ...           9        22       21   \n",
       "30052         0     0           0    ...          11        15       21   \n",
       "30053         0     0           0    ...          17         7       29   \n",
       "30054         0     0           0    ...          21        21       50   \n",
       "30055         0     0           0    ...          35         5       46   \n",
       "30056         1     0           0    ...          30         2       35   \n",
       "\n",
       "       HOSP_HR  HOSP_MN  CF1  CF2  CF3  FATALS  DRUNK_DR  \n",
       "0           99       99    0    0    0       2         0  \n",
       "1           99       99    0    0    0       1         0  \n",
       "2           99       99    0    0    0       1         0  \n",
       "3           99       99    0    0    0       2         0  \n",
       "4           99       99    0    0    0       1         0  \n",
       "5           99       99    0    0    0       1         0  \n",
       "6           88       88    0    0    0       1         0  \n",
       "7           99       99    0    0    0       1         0  \n",
       "8           88       88    0    0    0       1         1  \n",
       "9           88       88    0    0    0       1         0  \n",
       "10          99       99   20    0    0       1         1  \n",
       "11          88       88    0    0    0       1         0  \n",
       "12          99       99    0    0    0       1         0  \n",
       "13          88       88    0    0    0       1         0  \n",
       "14          88       88    0    0    0       1         1  \n",
       "15          99       99    0    0    0       1         0  \n",
       "16          88       88    0    0    0       1         0  \n",
       "17          88       88    0    0    0       1         0  \n",
       "18          88       88    0    0    0       1         0  \n",
       "19          88       88    0    0    0       1         1  \n",
       "20          88       88    0    0    0       1         1  \n",
       "21          99       99    0    0    0       1         0  \n",
       "22          99       99    0    0    0       1         0  \n",
       "23          99       99    0    0    0       1         0  \n",
       "24          88       88    0    0    0       1         0  \n",
       "25          99       99    0    0    0       1         0  \n",
       "26          88       88    0    0    0       1         1  \n",
       "27          88       88    0    0    0       1         0  \n",
       "28          99       99    0    0    0       1         0  \n",
       "29          99       99    0    0    0       1         0  \n",
       "...        ...      ...  ...  ...  ...     ...       ...  \n",
       "30027       12       25   26   19    0       1         0  \n",
       "30028       99       99    0    0    0       1         1  \n",
       "30029       99       99    0    0    0       1         1  \n",
       "30030       13       52    0    0    0       1         0  \n",
       "30031        7       51    0    0    0       3         0  \n",
       "30032       99       99    0    0    0       1         1  \n",
       "30033       88       88    0    0    0       1         1  \n",
       "30034       99       99    0    0    0       1         0  \n",
       "30035       99       99    0    0    0       1         0  \n",
       "30036       88       88    0    0    0       1         0  \n",
       "30037       88       88    0    0    0       1         1  \n",
       "30038       99       99    0    0    0       1         0  \n",
       "30039       10       16    0    0    0       2         0  \n",
       "30040        1       15    0    0    0       2         1  \n",
       "30041        7       42    0    0    0       1         0  \n",
       "30042       16       15    0    0    0       1         0  \n",
       "30043        7       47    0    0    0       1         1  \n",
       "30044       22       49   14    0    0       1         1  \n",
       "30045       19        2    0    0    0       1         0  \n",
       "30046       88       88    0    0    0       1         0  \n",
       "30047       88       88    0    0    0       1         0  \n",
       "30048       15       56    0    0    0       1         0  \n",
       "30049       88       88    0    0    0       1         0  \n",
       "30050       20       18    0    0    0       1         1  \n",
       "30051       88       88    0    0    0       1         1  \n",
       "30052       88       88    0    0    0       2         1  \n",
       "30053        8       15    0    0    0       1         0  \n",
       "30054       23        0    0    0    0       1         0  \n",
       "30055        6        7    0    0    0       2         1  \n",
       "30056       88       88   18    0    0       1         1  \n",
       "\n",
       "[30057 rows x 53 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"Data/Fatal_Motor_Vehicle_Accidents.csv\")\n",
    "df.head(30059)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "[CV] features__pca__n_components=1, features__univ_select__k=1, svm__C=0.1 \n",
      "[CV]  features__pca__n_components=1, features__univ_select__k=1, svm__C=0.1, score=0.960784, total=   0.0s\n",
      "[CV] features__pca__n_components=1, features__univ_select__k=1, svm__C=0.1 \n",
      "[CV]  features__pca__n_components=1, features__univ_select__k=1, svm__C=0.1, score=0.901961, total=   0.0s\n",
      "[CV] features__pca__n_components=1, features__univ_select__k=1, svm__C=0.1 \n",
      "[CV]  features__pca__n_components=1, features__univ_select__k=1, svm__C=0.1, score=0.979167, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] features__pca__n_components=1, features__univ_select__k=1, svm__C=1 \n",
      "[CV]  features__pca__n_components=1, features__univ_select__k=1, svm__C=1, score=0.941176, total=   0.0s\n",
      "[CV] features__pca__n_components=1, features__univ_select__k=1, svm__C=1 \n",
      "[CV]  features__pca__n_components=1, features__univ_select__k=1, svm__C=1, score=0.921569, total=   0.0s\n",
      "[CV] features__pca__n_components=1, features__univ_select__k=1, svm__C=1 \n",
      "[CV]  features__pca__n_components=1, features__univ_select__k=1, svm__C=1, score=0.979167, total=   0.0s\n",
      "[CV] features__pca__n_components=1, features__univ_select__k=1, svm__C=10 \n",
      "[CV]  features__pca__n_components=1, features__univ_select__k=1, svm__C=10, score=0.960784, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] features__pca__n_components=1, features__univ_select__k=1, svm__C=10 \n",
      "[CV]  features__pca__n_components=1, features__univ_select__k=1, svm__C=10, score=0.921569, total=   0.0s\n",
      "[CV] features__pca__n_components=1, features__univ_select__k=1, svm__C=10 \n",
      "[CV]  features__pca__n_components=1, features__univ_select__k=1, svm__C=10, score=0.979167, total=   0.0s\n",
      "[CV] features__pca__n_components=1, features__univ_select__k=2, svm__C=0.1 \n",
      "[CV]  features__pca__n_components=1, features__univ_select__k=2, svm__C=0.1, score=0.960784, total=   0.0s\n",
      "[CV] features__pca__n_components=1, features__univ_select__k=2, svm__C=0.1 \n",
      "[CV]  features__pca__n_components=1, features__univ_select__k=2, svm__C=0.1, score=0.921569, total=   0.0s\n",
      "[CV] features__pca__n_components=1, features__univ_select__k=2, svm__C=0.1 \n",
      "[CV]  features__pca__n_components=1, features__univ_select__k=2, svm__C=0.1, score=0.979167, total=   0.0s\n",
      "[CV] features__pca__n_components=1, features__univ_select__k=2, svm__C=1 \n",
      "[CV]  features__pca__n_components=1, features__univ_select__k=2, svm__C=1, score=0.960784, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] features__pca__n_components=1, features__univ_select__k=2, svm__C=1 \n",
      "[CV]  features__pca__n_components=1, features__univ_select__k=2, svm__C=1, score=0.921569, total=   0.0s\n",
      "[CV] features__pca__n_components=1, features__univ_select__k=2, svm__C=1 \n",
      "[CV]  features__pca__n_components=1, features__univ_select__k=2, svm__C=1, score=1.000000, total=   0.0s\n",
      "[CV] features__pca__n_components=1, features__univ_select__k=2, svm__C=10 \n",
      "[CV]  features__pca__n_components=1, features__univ_select__k=2, svm__C=10, score=0.980392, total=   0.0s\n",
      "[CV] features__pca__n_components=1, features__univ_select__k=2, svm__C=10 \n",
      "[CV]  features__pca__n_components=1, features__univ_select__k=2, svm__C=10, score=0.901961, total=   0.0s\n",
      "[CV] features__pca__n_components=1, features__univ_select__k=2, svm__C=10 \n",
      "[CV]  features__pca__n_components=1, features__univ_select__k=2, svm__C=10, score=1.000000, total=   0.0s\n",
      "[CV] features__pca__n_components=2, features__univ_select__k=1, svm__C=0.1 \n",
      "[CV]  features__pca__n_components=2, features__univ_select__k=1, svm__C=0.1, score=0.960784, total=   0.0s\n",
      "[CV] features__pca__n_components=2, features__univ_select__k=1, svm__C=0.1 \n",
      "[CV]  features__pca__n_components=2, features__univ_select__k=1, svm__C=0.1, score=0.901961, total=   0.0s\n",
      "[CV] features__pca__n_components=2, features__univ_select__k=1, svm__C=0.1 \n",
      "[CV]  features__pca__n_components=2, features__univ_select__k=1, svm__C=0.1, score=0.979167, total=   0.0s\n",
      "[CV] features__pca__n_components=2, features__univ_select__k=1, svm__C=1 \n",
      "[CV]  features__pca__n_components=2, features__univ_select__k=1, svm__C=1, score=0.980392, total=   0.0s\n",
      "[CV] features__pca__n_components=2, features__univ_select__k=1, svm__C=1 \n",
      "[CV]  features__pca__n_components=2, features__univ_select__k=1, svm__C=1, score=0.941176, total=   0.0s\n",
      "[CV] features__pca__n_components=2, features__univ_select__k=1, svm__C=1 \n",
      "[CV]  features__pca__n_components=2, features__univ_select__k=1, svm__C=1, score=0.979167, total=   0.0s\n",
      "[CV] features__pca__n_components=2, features__univ_select__k=1, svm__C=10 \n",
      "[CV]  features__pca__n_components=2, features__univ_select__k=1, svm__C=10, score=0.980392, total=   0.0s\n",
      "[CV] features__pca__n_components=2, features__univ_select__k=1, svm__C=10 \n",
      "[CV]  features__pca__n_components=2, features__univ_select__k=1, svm__C=10, score=0.941176, total=   0.0s\n",
      "[CV] features__pca__n_components=2, features__univ_select__k=1, svm__C=10 \n",
      "[CV]  features__pca__n_components=2, features__univ_select__k=1, svm__C=10, score=0.979167, total=   0.0s\n",
      "[CV] features__pca__n_components=2, features__univ_select__k=2, svm__C=0.1 \n",
      "[CV]  features__pca__n_components=2, features__univ_select__k=2, svm__C=0.1, score=0.980392, total=   0.0s\n",
      "[CV] features__pca__n_components=2, features__univ_select__k=2, svm__C=0.1 \n",
      "[CV]  features__pca__n_components=2, features__univ_select__k=2, svm__C=0.1, score=0.941176, total=   0.0s\n",
      "[CV] features__pca__n_components=2, features__univ_select__k=2, svm__C=0.1 \n",
      "[CV]  features__pca__n_components=2, features__univ_select__k=2, svm__C=0.1, score=0.979167, total=   0.0s\n",
      "[CV] features__pca__n_components=2, features__univ_select__k=2, svm__C=1 \n",
      "[CV]  features__pca__n_components=2, features__univ_select__k=2, svm__C=1, score=1.000000, total=   0.0s\n",
      "[CV] features__pca__n_components=2, features__univ_select__k=2, svm__C=1 \n",
      "[CV]  features__pca__n_components=2, features__univ_select__k=2, svm__C=1, score=0.960784, total=   0.0s\n",
      "[CV] features__pca__n_components=2, features__univ_select__k=2, svm__C=1 \n",
      "[CV]  features__pca__n_components=2, features__univ_select__k=2, svm__C=1, score=0.979167, total=   0.0s\n",
      "[CV] features__pca__n_components=2, features__univ_select__k=2, svm__C=10 \n",
      "[CV]  features__pca__n_components=2, features__univ_select__k=2, svm__C=10, score=0.980392, total=   0.0s\n",
      "[CV] features__pca__n_components=2, features__univ_select__k=2, svm__C=10 \n",
      "[CV]  features__pca__n_components=2, features__univ_select__k=2, svm__C=10, score=0.921569, total=   0.0s\n",
      "[CV] features__pca__n_components=2, features__univ_select__k=2, svm__C=10 \n",
      "[CV]  features__pca__n_components=2, features__univ_select__k=2, svm__C=10, score=1.000000, total=   0.0s\n",
      "[CV] features__pca__n_components=3, features__univ_select__k=1, svm__C=0.1 \n",
      "[CV]  features__pca__n_components=3, features__univ_select__k=1, svm__C=0.1, score=0.980392, total=   0.0s\n",
      "[CV] features__pca__n_components=3, features__univ_select__k=1, svm__C=0.1 \n",
      "[CV]  features__pca__n_components=3, features__univ_select__k=1, svm__C=0.1, score=0.941176, total=   0.0s\n",
      "[CV] features__pca__n_components=3, features__univ_select__k=1, svm__C=0.1 \n",
      "[CV]  features__pca__n_components=3, features__univ_select__k=1, svm__C=0.1, score=0.979167, total=   0.0s\n",
      "[CV] features__pca__n_components=3, features__univ_select__k=1, svm__C=1 \n",
      "[CV]  features__pca__n_components=3, features__univ_select__k=1, svm__C=1, score=1.000000, total=   0.0s\n",
      "[CV] features__pca__n_components=3, features__univ_select__k=1, svm__C=1 \n",
      "[CV]  features__pca__n_components=3, features__univ_select__k=1, svm__C=1, score=0.941176, total=   0.0s\n",
      "[CV] features__pca__n_components=3, features__univ_select__k=1, svm__C=1 \n",
      "[CV]  features__pca__n_components=3, features__univ_select__k=1, svm__C=1, score=0.979167, total=   0.0s\n",
      "[CV] features__pca__n_components=3, features__univ_select__k=1, svm__C=10 \n",
      "[CV]  features__pca__n_components=3, features__univ_select__k=1, svm__C=10, score=1.000000, total=   0.0s\n",
      "[CV] features__pca__n_components=3, features__univ_select__k=1, svm__C=10 \n",
      "[CV]  features__pca__n_components=3, features__univ_select__k=1, svm__C=10, score=0.921569, total=   0.0s\n",
      "[CV] features__pca__n_components=3, features__univ_select__k=1, svm__C=10 \n",
      "[CV]  features__pca__n_components=3, features__univ_select__k=1, svm__C=10, score=1.000000, total=   0.0s\n",
      "[CV] features__pca__n_components=3, features__univ_select__k=2, svm__C=0.1 \n",
      "[CV]  features__pca__n_components=3, features__univ_select__k=2, svm__C=0.1, score=0.980392, total=   0.0s\n",
      "[CV] features__pca__n_components=3, features__univ_select__k=2, svm__C=0.1 \n",
      "[CV]  features__pca__n_components=3, features__univ_select__k=2, svm__C=0.1, score=0.941176, total=   0.0s\n",
      "[CV] features__pca__n_components=3, features__univ_select__k=2, svm__C=0.1 \n",
      "[CV]  features__pca__n_components=3, features__univ_select__k=2, svm__C=0.1, score=0.979167, total=   0.0s\n",
      "[CV] features__pca__n_components=3, features__univ_select__k=2, svm__C=1 \n",
      "[CV]  features__pca__n_components=3, features__univ_select__k=2, svm__C=1, score=1.000000, total=   0.0s\n",
      "[CV] features__pca__n_components=3, features__univ_select__k=2, svm__C=1 \n",
      "[CV]  features__pca__n_components=3, features__univ_select__k=2, svm__C=1, score=0.960784, total=   0.0s\n",
      "[CV] features__pca__n_components=3, features__univ_select__k=2, svm__C=1 \n",
      "[CV]  features__pca__n_components=3, features__univ_select__k=2, svm__C=1, score=0.979167, total=   0.0s\n",
      "[CV] features__pca__n_components=3, features__univ_select__k=2, svm__C=10 \n",
      "[CV]  features__pca__n_components=3, features__univ_select__k=2, svm__C=10, score=1.000000, total=   0.0s\n",
      "[CV] features__pca__n_components=3, features__univ_select__k=2, svm__C=10 \n",
      "[CV]  features__pca__n_components=3, features__univ_select__k=2, svm__C=10, score=0.921569, total=   0.0s\n",
      "[CV] features__pca__n_components=3, features__univ_select__k=2, svm__C=10 \n",
      "[CV]  features__pca__n_components=3, features__univ_select__k=2, svm__C=10, score=1.000000, total=   0.0s\n",
      "Pipeline(steps=[('features', FeatureUnion(n_jobs=1,\n",
      "       transformer_list=[('pca', PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('univ_select', SelectKBest(k=2, score_func=<function f_classif at 0x0000022F6C1B29D8>))],\n",
      "       transfo...,\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  54 out of  54 | elapsed:    1.7s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "selection = SelectKBest(k=1)\n",
    "\n",
    "combined_features = FeatureUnion([(\"pca\", pca), (\"univ_select\", selection)])\n",
    "\n",
    "X_features = combined_features.fit(X, y).transform(X)\n",
    "\n",
    "svm = SVC(kernel=\"linear\")\n",
    "\n",
    "pipeline = Pipeline([(\"features\", combined_features), (\"svm\", svm)])\n",
    "\n",
    "param_grid = dict(features__pca__n_components=[1, 2, 3],\n",
    "                  features__univ_select__k=[1, 2],\n",
    "                  svm__C=[0.1, 1, 10])\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, verbose=10)\n",
    "grid_search.fit(X, y)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
